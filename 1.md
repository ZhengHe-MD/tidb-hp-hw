# 第 1 周

## 题目描述

本地下载 TiDB，TiKV，PD 源代码，改写源代码并编译部署以下环境：

* 1 TiDB
* 1 PD
* 3 TiKV

改写后：使得 TiDB 启动事务时，能打印出一个 "hello transaction" 的日志。



**输出：一篇文章介绍以上过程**

## 计算环境

* macOS Catalina
* 2.7 GHz Dual-Core Intel Core i5
* 8 GB 1867 MHz DDR3
* Macintosh HD 128 GB

## 过程描述

分两步：

1. 按要求搭建好环境后，能用标准 MySQL 客户端连接
2. 阅读、修改 TiDB 源码，将自己触发的事务信息打印 (即 hello transaction)

### 环境搭建

#### Rust & Go

安装 Rust，因为TiKV 使用 Rust 编码：

```sh
$ curl --proto '=https' --tlsv1.2 https://sh.rustup.rs -sSf | sh
```

安装 Go：由于平时工作使用的是 Go1.12，PD 和 TiDB 都要求 Go1.13，因此这里涉及到 Go 语言环境切换。因为之前用过 rvm (ruby)，nvm (node)，猜测应该有个 gvm (go)，结果果然有：

```sh
$ bash < <(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer)
$ source /Users/hezheng/.gvm/scripts/gvm # 可以加入 ./zshrc 中
$ gvm list
gvm gos (installed)

=> system
$ gvm install go1.13
$ gvm use go1.13
$ go version
go version go1.13 darwin/amd64
```

#### 编译 TiKV，PD 和 TiDB

##### TiKV

下载源码：

```sh
$ git clone https://github.com/tikv/tikv.git
```

编译：

```sh
$ cd tikv && make build
```

编译完以后多出 `target` 文件夹，简单看一下结构：

```sh
$ tree target -L 2

target
└── debug
    ├── build
    ├── deps
    ├── examples
    ├── incremental
    ├── libcmd.d
    ├── libcmd.rlib
    ├── tikv-ctl
    ├── tikv-ctl.d
    ├── tikv-ctl.dSYM -> deps/tikv_ctl.dSYM
    ├── tikv-server
    ├── tikv-server.d
    └── tikv-server.dSYM -> deps/tikv_server.dSYM
```

##### PD

下载源码：

```sh
$ git clone https://github.com/pingcap/pd.git
```

编译：

```sh
$ cd pd && make
```

编译完以后多出 `bin` 文件夹，简单看一下结构：

```sh
$ tree bin
bin
├── pd-ctl
├── pd-recover
└── pd-server
```

#### TiDB

下载源码：

```sh
$ git clone https://github.com/pingcap/tidb.git
```

编译：

```sh
$ cd tidb && make server
```

编译完以后多出 `bin` 文件夹，简单看一下结构：

```sh
$ tree bin
bin
└── tidb-server
```

#### 启动 PD、TiKV 和 TiDB

根据 TiKV 官方[文档](https://tikv.org/docs/4.0/tasks/deploy/binary/)，先启动 PD 后启动 TiKV，TiDB 与二者相对独立。

##### PD

根据文档给出的参数启动 PD：

```sh
$ cd pd/bin
$ ./pd-server --name=pd1 \
              --data-dir=pd1 \
              --client-urls="http://127.0.0.1:2379" \
              --peer-urls="http://127.0.0.1:2380" \
              --initial-cluster="pd1=http://127.0.0.1:2380"
```

一切顺利，可以在标准输出中看到一堆日志：

```
...
[2020/08/15 17:57:41.127 +08:00] [INFO] [server.go:1150] ["PD cluster leader is ready to serve"] [pd-leader-name=pd1]
...
```

##### TiKV

根据文档给出的参数启动 TiKV：

```sh
$ cd tikv/target/debug
$ ./tikv-server --pd-endpoints="127.0.0.1:2379" \
               	--addr="127.0.0.1:20160" \
                --data-dir=tikv1
```

失败了，可以看到这行日志：

```sh
...
[2020/08/15 17:59:38.459 +08:00] [FATAL] [server.rs:920] ["the maximum number of open file descriptors is too small, got 256, expect greater or equal to 82920"]
```

根据 [TiDB 技术内幕 - 说存储](https://pingcap.com/blog-cn/tidb-internal-1/) 的阐述，TiKV 的存储层托管给 RocksDB，我对 RocksDB 的了解仅限于它是基于 LSM-Tree 构建的 (曾经在自己的一篇[博文](https://zhenghe-md.github.io/blog/2020/02/26/Log-Structured-Merge-LSM-Tree-Usages-in-KV-Stores/)中总结过)，这里暂且理解成 RocksDB 对 SST 有分块策略，单进程 256 个文件描述符不够用，参考这篇[文章](https://k6.io/docs/misc/fine-tuning-os)：

```sh
$ sudo launchctl limit maxfiles 82920 200000
$ sudo ulimit -Sn 82920
```

再次执行启动命令，就能看到：

```sh
...
[2020/08/15 18:19:19.889 +08:00] [INFO] [server.rs:244] ["TiKV is ready to serve"]
...
```

一个 TiKV 实例无法完成 Raft Group 的选举过程，我们至少需要 3 个实例：

```sh
$ ./tikv-server --pd-endpoints="127.0.0.1:2379" \
                --addr="127.0.0.1:20161" \
                --data-dir=tikv2
$ ./tikv-server --pd-endpoints="127.0.0.1:2379" \
                --addr="127.0.0.1:20162" \
                --data-dir=tikv3
```

##### TiDB

启动 TiDB 时需要指定 store 类型为 tikv，并且告诉它 PD 的地址：

```sh
$ cd tidb/bin
$ ./tidb-server --store=tikv \
                --path="127.0.0.1:2379"
```

可以看到这条日志：

```sh
...
[2020/08/15 20:28:39.984 +08:00] [INFO] [server.go:235] ["server is running MySQL protocol"] [addr=0.0.0.0:4000]
...
```

大概能够说明 TiDB 启动成功了。当然，我们可以进一步验证一下 (这里用到 mycli，交互更友好一些)：

```sh
$ mycli -h 127.0.0.1 -P 4000 -uroot

mysql root@127.0.0.1:(none)> SHOW DATABASES;
+--------------------+
| Database           |
+--------------------+
| INFORMATION_SCHEMA |
| METRICS_SCHEMA     |
| PERFORMANCE_SCHEMA |
| mysql              |
| test               |
+--------------------+
mysql root@127.0.0.1:(none)> SELECT `TYPE`, `INSTANCE`, `STATUS_ADDRESS`, `VERSION` FROM `INFORMATION_SCHEMA`.`CLUSTER_INFO`;

+------+-----------------+-----------------+--------------+
| TYPE | INSTANCE        | STATUS_ADDRESS  | VERSION      |
+------+-----------------+-----------------+--------------+
| tidb | 0.0.0.0:4000    | 0.0.0.0:10080   | 4.0.0-beta.2 |
| pd   | 127.0.0.1:2379  | 127.0.0.1:2379  | 4.1.0-alpha  |
| tikv | 127.0.0.1:20161 | 127.0.0.1:20180 | 4.1.0-alpha  |
| tikv | 127.0.0.1:20162 | 127.0.0.1:20180 | 4.1.0-alpha  |
| tikv | 127.0.0.1:20160 | 127.0.0.1:20180 | 4.1.0-alpha  |
+------+-----------------+-----------------+--------------+
```

### hello transaction

根据 [TiDB 技术内幕 - 说计算](https://pingcap.com/blog-cn/tidb-internal-2/) 一文描述，TiDB 兼容 MySQL Server Protocol，跟一下 server/server.go 中的 main 函数，大概就可以看出基本的服务器模型，每个连接经过校验后会由单独的一个 goroutine 处理，顺着处理流程：

```
   server.Run 
=> server.onConn
=> clientConn.Run 
=> clientConn.dispatch
=> clientConn.handleQuery
=> clientConn.handleStmt
=> TiDBContext.ExecuteStmt
=> session.ExecuteStmt
```

修改 session.ExecuteStmt：

```go
func (s *session) ExecuteStmt(ctx context.Context, stmtNode ast.StmtNode) (sqlexec.RecordSet, error) {
  // ...
	// opentracing staff

	logutil.Logger(ctx).Info("hello transaction", zap.String("sql", stmtNode.Text()))
  // transaction logic
}
```

重新编译 TiDB 后启动，这次将日志放入日志文件中查看：

```sh
$ make server
$ cd bin/
$ ./tidb-server --store=tikv \
               --path="127.0.0.1:2379" \
               --log-file tidb-server.log
```

马上就能够看到许多 "hello transaction" 日志，如：

```
["hello transaction"] [sql="select variable_value from mysql.tidb where variable_name = 'sy    stem_tz'"]
["hello transaction"] [sql="select HIGH_PRIORITY table_id, is_index, hist_id, distinct_coun    t, version, null_count, cm_sketch, tot_col_size, stats_ver, correlation, flag, last_analyze_pos from mysql.stats_histograms"]
```

这些应该是 TiDB 内部执行的 SQL  语句，维护系统元信息，可以暂时不关心。现在尝试创建测试数据库和数据表：

```sql
mysql root@127.0.0.1:zhenghe> CREATE DATABASE `zhenghe`;
mysql root@127.0.0.1:zhenghe> USE `zhenghe`;
mysql root@127.0.0.1:zhenghe> CREATE TABLE `student` (
	`id` BIGINT UNSIGNED NOT NULL AUTO_INCREMENT COMMENT 'id',
  `name` VARCHAR(16) NOT NULL COMMENT '姓名',
  `age` INT NOT NULL COMMENT '年龄',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uniq_name` (`name`),
  KEY `idx_age` (`age`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 AUTO_INCREMENT=10000 COMMENT='学生表';
mysql root@127.0.0.1:zhenghe> INSERT INTO `student` (`name`, `age`) VALUES ('郑鹤', 28);
```

可以看到相关日志：

```sh
[2020/08/15 21:20:14.659 +08:00] [INFO] [session.go:1125] ["hello transaction"] [conn=1] [sql="CREATE DATABASE `zhenghe`"]
[2020/08/15 21:20:21.580 +08:00] [INFO] [session.go:1125] ["hello transaction"] [conn=1] [sql="CREATE TABLE `student` (\n\t`id` BIGINT UNSIGNED NOT N    ULL AUTO_INCREMENT COMMENT 'id',\n  `name` VARCHAR(16) NOT NULL COMMENT '姓名',\n  `age` INT NOT NULL COMMENT '年龄',\n  PRIMARY KEY (`id`),\n  UNIQU    E KEY `uniq_name` (`name`),\n  KEY `idx_age` (`age`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 AUTO_INCREMENT=10000 COMMENT='学生表'"]
[2020/08/15 21:23:50.473 +08:00] [INFO] [session.go:1125] ["hello transaction"] [conn=3] [sql="INSERT INTO `student` (`name`, `age`) VALUES ('郑鹤',     28)"]
```

在 [TiDB 技术内幕 - 说存储](https://pingcap.com/blog-cn/tidb-internal-1/) 一文中提到，每张表都有一个 id，顺便在 INFORMATION_SCHEMA  中找了一下，的确有一张：

```sql
mysql root@127.0.0.1:zhenghe> USE INFORMATION_SCHEMA;
mysql root@127.0.0.1:zhenghe> SELECT `TABLE_NAME`, `TIDB_TABLE_ID` FROM `INFORMATION_SCHEMA.TABLES` WHERE TABLE_NAME = "student";

+------------+---------------+
| TABLE_NAME | TIDB_TABLE_ID |
+------------+---------------+
| student    | 54            |
+------------+---------------+
```

顺便从日志中 grep 一下，可以看到类似的日志：

```sh
[2020/08/15 21:23:49.497 +08:00] [INFO] [session.go:1125] ["hello transaction"] [sql="select stats_name, db, status, type, column_ids, scalar_stats,     blob_stats, version from mysql.stats_extended where table_id = 54 and status in (1, 2) and version > 0"]
[2020/08/15 21:24:04.533 +08:00] [INFO] [session.go:1125] ["hello transaction"] [sql="update mysql.stats_meta set version = 418774474952015876, count     = count + 1, modify_count = modify_count + 1 where table_id = 54"]
```

看着像是数据字典信息维护相关的信息，日后再验证吧。最后还想看一下数据究竟写到哪个 TiKV 上了：

```sql
mysql root@127.0.0.1:zhenghe> SELECT `REGION_ID`, `TABLE_ID`, `IS_INDEX`, `INDEX_ID`, `INDEX_NAME` FROM `INFORMATION_SCHEMA.TIKV_REGION_STATUS` WHERE `TABLE_ID` = 54;

+-----------+----------+----------+----------+------------+
| REGION_ID | TABLE_ID | IS_INDEX | INDEX_ID | INDEX_NAME |
+-----------+----------+----------+----------+------------+
| 2         | 54       | 1        | 1        | uniq_name  |
| 2         | 54       | 1        | 2        | idx_age    |
| 2         | 54       | 0        | <null>   | <null>     |
+-----------+----------+----------+----------+------------+

mysql root@127.0.0.1:zhenghe> SELECT * FROM INFORMATION_SCHEMA.`TIKV_REGION_PEERS` WHERE REGION_ID = 2;
+-----------+---------+----------+------------+-----------+--------+--------------+
| REGION_ID | PEER_ID | STORE_ID | IS_LEARNER | IS_LEADER | STATUS | DOWN_SECONDS |
+-----------+---------+----------+------------+-----------+--------+--------------+
| 2         | 3       | 1        | 0          | 0         | NORMAL | <null>       |
| 2         | 1001    | 4        | 0          | 1         | NORMAL | <null>       |
| 2         | 1002    | 5        | 0          | 0         | NORMAL | <null>       |
+-----------+---------+----------+------------+-----------+--------+--------------+
```

可以看到 `student` 表有关的数据都在 REGION 2 上，而 REGION 2  的 Leader 是 STORE 4。同时 REGION 2 的两个副本分别分布在另外两个不同的 Store 上，符合 [TiDB 技术内幕 - 谈调度](https://pingcap.com/blog-cn/tidb-internal-3/) 的介绍。

## 参考

* [The Rust Programming Language](https://github.com/rust-lang)
* [moovweb/gvm](https://github.com/moovweb/gvm)
* [TiKV: Binary Deployment](https://tikv.org/docs/4.0/tasks/deploy/binary/)
*  [TiDB 技术内幕 - 说存储](https://pingcap.com/blog-cn/tidb-internal-1/)
* [TiDB 技术内幕 - 说计算](https://pingcap.com/blog-cn/tidb-internal-2/)
* [TiDB 技术内幕 - 谈调度](https://pingcap.com/blog-cn/tidb-internal-3/)
* [Log Structured Merge (LSM) Tree & Usages in KV Stores](https://zhenghe-md.github.io/blog/2020/02/26/Log-Structured-Merge-LSM-Tree-Usages-in-KV-Stores/)
* [fine-tuning-os](https://k6.io/docs/misc/fine-tuning-os)
* [dbcli/mycli](https://github.com/dbcli/mycli.git)

